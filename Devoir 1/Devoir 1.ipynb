{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "Ceci sont les importations que nous aurons besoin pour le projet. Nous utiliserons SKlearn tel que indiqué par le professeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#classification\n",
    "from sklearn.neighbors import KNeighborsClassifier #k-plus proches voisins\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "\n",
    "#Partitionnement\n",
    "from sklearn.cluster import AgglomerativeClustering #Regroupement hiérarchique (Partitionnement binaire)\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "\n",
    "#réduction de dimensionnalité\n",
    "from sklearn.decomposition import KernelPCA #ce n'est pas PCoA mais on peut l'utiliser pour que le résultat soit le même\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pour commencer le projet, nous allons créer une baseline pour MNIST en faisant la distance euclidienne pour tous les algorithmes que le projet nous indique. Donc nous le ferons pour:\n",
    "● k-medoïde\n",
    "● Partition binaire (Regroupement hiérarchique)\n",
    "● PCoA (c'est un cas particulier de MDS)\n",
    "● Isomap\n",
    "● KNN (k-plus proches voisins)\n",
    "\n",
    "Nous allons aussi importer MNIST et ADULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://notebook.community/francesco-mannella/neunet-basics/course/mnist\n",
    "# import the mnist class\n",
    "from mnist import MNIST\n",
    "\n",
    "# init with the 'data' dir\n",
    "mndata = MNIST('.\\data')\n",
    "\n",
    "# Load data\n",
    "mndata.load_training()\n",
    "mndata.load_testing()\n",
    "\n",
    "# The number of pixels per side of all images\n",
    "img_side = 28\n",
    "\n",
    "# Each input is a raw vector.\n",
    "# The number of units of the network\n",
    "# corresponds to the number of input elements\n",
    "n_mnist_pixels = img_side*img_side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ici on vérifie que le dataset à bien téléchargé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "\n",
    "# Define the number of samples to take\n",
    "num_samples = 10\n",
    "\n",
    "# create a figure where we will store all samples\n",
    "plt.figure(figsize=(10,1))\n",
    "\n",
    "# Iterate over samples indices\n",
    "for sample in range(num_samples) :\n",
    "\n",
    "    # The image corresponding to the 'sample' index\n",
    "    img = mndata.train_images[sample]\n",
    "\n",
    "    # The label of the image\n",
    "    label = mndata.train_labels[sample]\n",
    "\n",
    "    # The image is stored as a rolled vector,\n",
    "    # we have to roll it back in a matrix\n",
    "    aimg = np.array(img).reshape(img_side, img_side)\n",
    "\n",
    "    # Open a subplot for each sample\n",
    "    plt.subplot(1, num_samples, sample+1)\n",
    "\n",
    "    # The corresponding digit is the title of the plot\n",
    "    plt.title(label)\n",
    "\n",
    "    # We use imshow to plot the matrix of pixels\n",
    "    plt.imshow(aimg, interpolation = 'none',\n",
    "        aspect = 'auto', cmap = cm.binary)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ici nous ferons l'algorithme de k-medoïde avec la distance euclidienne pour MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.utils import read_sample\n",
    "from pyclustering.samples.definitions import FCPS_SAMPLES\n",
    "from pyclustering.utils.metric import distance_metric, type_metric\n",
    "from mnist import MNIST\n",
    "\n",
    "# init with the 'data' dir\n",
    "mndata = MNIST('.\\data')\n",
    "\n",
    "# Load data\n",
    "mndata.load_training()\n",
    "mndata.load_testing()\n",
    "\n",
    "# Load list of points for cluster analysis.\n",
    "sample = read_sample(FCPS_SAMPLES.SAMPLE_TWO_DIAMONDS)\n",
    "\n",
    "# Set random initial medoids.\n",
    "initial_medoids = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "# create Minkowski distance metric with degree equals to '2'\n",
    "metric = distance_metric(type_metric.MINKOWSKI, degree=2)\n",
    "\n",
    "# create K-Medoids algorithm with specific distance metric\n",
    "kmedoids_instance = kmedoids(sample, initial_medoids, metric=metric)\n",
    "\n",
    "# run cluster analysis and obtain results\n",
    "kmedoids_instance.process()\n",
    "clusters = kmedoids_instance.get_clusters()\n",
    "\n",
    "# Show allocated clusters.\n",
    "#print(sample)\n",
    "print(mndata)\n",
    "\n",
    "# Display clusters.\n",
    "visualizer = cluster_visualizer()\n",
    "visualizer.append_clusters(clusters, sample)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ici nous ferons la partition binaire avec la distance euclidienne pour MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agglo = AgglomerativeClustering(n_clusters=9, affinity='euclidean', linkage='ward')\n",
    "agglo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # https://medium.com/@ali.soleymani.co/beyond-scikit-learn-is-it-time-to-retire-k-means-and-use-this-method-instead-b8eb9ca9079a\n",
    "# kmedo = KMedoids(n_clusters = 9, random_state=1)\n",
    "# kmedo.fit(mndata.train_images, mndata.train_labels)\n",
    "# # Doing predictions on the test set\n",
    "# y_hat = kmedo.predict(mndata.test_images)\n",
    "# acc = accuracy_score(mndata.test_labels, y_hat)\n",
    "# print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}